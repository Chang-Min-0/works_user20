import os
import uuid
import json
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# AZURESEARCH_FIELDS_CONTENT: ìì‹ ì˜ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ ëŒ€ìƒì„ ì˜ë¯¸í•˜ëŠ” í•„ë“œëª…
# AZURESEARCH_FIELDS_CONTENT_VECTOR: 'AZURESEARCH_FIELDS_CONTENT' ì˜ ì„ë² ë”©ì„ ì˜ë¯¸í•˜ëŠ” í•„ë“œëª…
os.environ['AZURESEARCH_FIELDS_CONTENT'] = "chunk"
os.environ['AZURESEARCH_FIELDS_CONTENT_VECTOR'] = "text_vector"

from openai import AzureOpenAI
from langchain_community.vectorstores.azuresearch import AzureSearch
from langchain_openai import AzureOpenAIEmbeddings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI ì„¤ì •
class AzureConfig:
    API_TYPE = os.getenv("AZURE_API_TYPE", "azure")
    API_BASE = os.getenv("AZURE_ENDPOINT")
    API_VERSION = os.getenv("AZURE_API_VERSION", "2024-12-01-preview")
    API_KEY = os.getenv("AZURE_API_KEY")
    MODEL = os.getenv("AZURE_MODEL")
    TEMPERATURE = 0.8
    EMBEDDING_DEPLOYMENT = os.getenv("EMBEDDING_DEPLOYENT_NAME")

# Azure AI Search ì„¤ì •
class AzureSearchConfig:
    SERVICE = os.getenv("AZURE_SEARCH_SERVICE")
    KEY = os.getenv("AZURE_SEARCH_KEY")
    INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")
    AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
    ENDPOINT = f"https://{SERVICE}.search.windows.net" if SERVICE else None
    
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = AzureOpenAI(
    api_key=AzureConfig.API_KEY,
    api_version=AzureConfig.API_VERSION,
    azure_endpoint=AzureConfig.API_BASE
)

class VectorStoreManager:
    """ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self._initialize_embeddings()
        self._initialize_vector_store()
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ì´ˆê¸°í™”"""
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment=AzureConfig.EMBEDDING_DEPLOYMENT,
            openai_api_version=AzureConfig.API_VERSION,
            azure_endpoint=AzureConfig.API_BASE,
            api_key=AzureConfig.API_KEY,
        )
    
    def _initialize_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        self.vector_store = AzureSearch(
            azure_search_endpoint=AzureSearchConfig.AZURE_SEARCH_ENDPOINT,
            azure_search_key=AzureSearchConfig.KEY,
            index_name=AzureSearchConfig.INDEX_NAME,
            embedding_function=self.embeddings.embed_query,
            search_type="hybrid",
            additional_search_client_options={
                "retry_total": 3, 
                "api_version": "2025-05-01-preview"
            },
        )
    
    def get_retriever(self, top_k=3):
        """ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ ë°˜í™˜"""
        return self.vector_store.as_retriever(
            search_type="hybrid",
            k=top_k
        )


class SimpleChatbotManager:
    """ì±„íŒ…ë´‡ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model = AzureConfig.MODEL
        self.temperature = AzureConfig.TEMPERATURE
        self.session_id = str(uuid.uuid4())
        self.conversation_history = []
        self.system_prompt = (
            "ë‹¹ì‹ ì€ Azure OpenAIì™€ Azure AI Searchë¥¼ í™œìš©í•œ RAG(Retrieval-Augmented Generation)ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ìì²´ ì§€ì‹ì´ ì•„ë‹Œ RAG ê¸°ë°˜ì˜ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. "
            "í•­ìƒ ê²€ìƒ‰ëœ ë‚´ìš© ì•ˆì—ì„œ ìµœëŒ€í•œ ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ì •ë³´ë¥¼ ìš”ì•½í•´ ì „ë‹¬í•˜ê³ , "
            "ë‹µë³€ì— í™œìš©í•œ ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì„¸ìš”. "
            "ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´, ì´ë¥¼ ì†”ì§í•˜ê²Œ ê³ ì§€í•˜ê³  ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:\n"
            "1. ì£¼ìš” ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ì¡°í™”ëœ ë‹¨ë½ìœ¼ë¡œ ì œì‹œ\n"
            "2. ì¤‘ìš”í•œ ê°œë…ì´ë‚˜ ìš©ì–´ëŠ” ë§ˆí¬ë‹¤ìš´ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°\n"
            "3. í•„ìš”í•œ ê²½ìš° ë‚´ìš©ì„ ëª©ë¡í™”í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ\n"
            "4. ì‘ë‹µ ë§ˆì§€ë§‰ì— 'ì¶œì²˜: [ë¬¸ì„œëª…]' í˜•ì‹ìœ¼ë¡œ RAGì°¸ê³  ì¶œì²˜ ëª…ì‹œ"
        )
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = AzureOpenAI(
            api_key=AzureConfig.API_KEY,
            api_version=AzureConfig.API_VERSION,
            azure_endpoint=AzureConfig.API_BASE
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.vector_store_manager = self._init_vector_store()
        
    def _init_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            if all([AzureSearchConfig.SERVICE, AzureSearchConfig.KEY, AzureSearchConfig.INDEX_NAME]):
                vector_store = VectorStoreManager()
                print("âœ… Azure AI Search ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
                return vector_store
            else:
                print("âš ï¸ Azure AI Search í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return None
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def search_documents(self, query: str, top: int = 3) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.vector_store_manager:
            return [{"error": "Azure AI Searchê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}]
        
        try:
            retriever = self.vector_store_manager.get_retriever(top_k=top)
            docs = retriever.invoke(query)
            
            # Document ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            results = []
            for doc in docs:
                results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })
            return results
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return [{"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}]
    
    def _prepare_search_context(self, search_results):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not search_results:
            return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
            
        search_context = "ë‹¤ìŒì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n"
        for i, result in enumerate(search_results):
            search_context += f"[{i+1}] {json.dumps(result, ensure_ascii=False)}\n\n"
        search_context += "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        return search_context
    
    async def _execute_search(self, user_message: str):
        """ê²€ìƒ‰ ì‹¤í–‰ ë° ê²°ê³¼ ì²˜ë¦¬"""
        search_results = await self.search_documents(user_message)
        
        # ì˜¤ë¥˜ê°€ ì—†ëŠ” ê²€ìƒ‰ ê²°ê³¼ì¸ì§€ í™•ì¸
        has_error = any(isinstance(result.get("error", None), str) for result in search_results)
        
        if search_results and not has_error:
            return self._prepare_search_context(search_results)
        else:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
    
    async def get_response_with_search(self, user_message: str, use_search: bool = True) -> str:
        """AI ì‘ë‹µ ìƒì„± (ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨)"""
        try:
            print(f"ğŸ”„ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘: {user_message[:50]}...")
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.conversation_history.append({"role": "user", "content": user_message})
            
            # ë©”ì‹œì§€ ì¤€ë¹„
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # ê²€ìƒ‰ ê¸°ëŠ¥ ì‚¬ìš© ì‹œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
            if use_search and self.vector_store_manager:
                search_context = await self._execute_search(user_message)
                messages.append({"role": "system", "content": search_context})
        
            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            messages.extend(self.conversation_history)
            
            # OpenAI API í˜¸ì¶œ (ìµœì‹  ë°©ì‹)
            response = self._call_openai_api(messages)
            reply = response.choices[0].message.content
            
            # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.conversation_history.append({"role": "assistant", "content": reply})
            
            print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(reply)}ì")
            return reply

        except Exception as e:
            error_msg = f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    def _call_openai_api(self, messages):
        """OpenAI API í˜¸ì¶œ (ìµœì‹  ë²„ì „)"""
        return self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
        )

    def reset_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.session_id = str(uuid.uuid4())
        print("ğŸ”„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ")

    def get_agent_info(self) -> Dict[str, Any]:
        """Agent ì •ë³´ ë°˜í™˜"""
        return {
            "model": self.model,
            "temperature": self.temperature,
            "session_id": self.session_id,
            "conversation_turns": len(self.conversation_history) // 2,
            "search_enabled": self.vector_store_manager is not None
        }
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """í˜„ì¬ ëŒ€í™” ì„¸ì…˜ì˜ ì „ì²´ ê¸°ë¡ ë°˜í™˜"""
        return self.conversation_history
    
    def set_system_prompt(self, prompt: str) -> None:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •"""
        self.system_prompt = prompt
        print(f"âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_chatbot_manager_instance = None

def get_chatbot_manager() -> SimpleChatbotManager:
    """ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ Chatbot ê´€ë¦¬ì ë°˜í™˜"""
    global _chatbot_manager_instance
    if _chatbot_manager_instance is None:
        _chatbot_manager_instance = SimpleChatbotManager()
    return _chatbot_manager_instance